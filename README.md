# Toxic Spans Detection
Rapid growth and increased interaction on social media promoted good awareness and as well caused some damage to society. One major concern is the increase in negative comments and hate speeches posted on social media and online discussion forums. A traditional approach is to identify these harsh comments manually by human moderators and then either filter or remove the comments. This will help promote a safe environment for other users to participate in online discussions. However, the rapid growth in volumes of the data generated on social media and other platforms makes it tedious and complicated for human moderators to identify toxic posts. There is a pressing need to automate the process of annotating such offensive posts. Majority of the currently available toxicity detection datasets and models focus on classifying entire comment or document as toxic. They do not identify the actual sequence of words or toxic spans that actually make the text toxic. This necessity has motivated the SemEval-2021 organizers to design a task called as “Toxic Spans Detection”!
